{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.color_palette()\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 4\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Read and prepare the dataset from the University of Nevada, UNR-IDD.csv, downloaded from: https://drive.google.com/file/d/1Xumpy7su7C5_Yo00PwjeJfJyaMU6Cn8w/view?usp=sharing. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37412 ../data/raw/UNR-IDD.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%sh\n",
    "wc -l ../data/raw/UNR-IDD.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data as pd dataframe\n",
    "\n",
    "rawdata_path = \"../data/raw/UNR-IDD.csv\"\n",
    "raw_df = pd.read_csv(rawdata_path, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw_df as csv to folder for further use\n",
    "\n",
    "raw_df.to_csv(\"../data/raw/raw_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Switch ID</th>\n",
       "      <th>Port Number</th>\n",
       "      <th>Received Packets</th>\n",
       "      <th>Received Bytes</th>\n",
       "      <th>Sent Bytes</th>\n",
       "      <th>Sent Packets</th>\n",
       "      <th>Port alive Duration (S)</th>\n",
       "      <th>Packets Rx Dropped</th>\n",
       "      <th>Packets Tx Dropped</th>\n",
       "      <th>Packets Rx Errors</th>\n",
       "      <th>...</th>\n",
       "      <th>Unknown Load/Latest</th>\n",
       "      <th>Latest bytes counter</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>Table ID</th>\n",
       "      <th>Active Flow Entries</th>\n",
       "      <th>Packets Looked Up</th>\n",
       "      <th>Packets Matched</th>\n",
       "      <th>Max Size</th>\n",
       "      <th>Label</th>\n",
       "      <th>Binary Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of:000000000000000c</td>\n",
       "      <td>Port#:1</td>\n",
       "      <td>132</td>\n",
       "      <td>9181</td>\n",
       "      <td>6311853</td>\n",
       "      <td>238</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>767</td>\n",
       "      <td>688</td>\n",
       "      <td>-1</td>\n",
       "      <td>TCP-SYN</td>\n",
       "      <td>Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of:000000000000000c</td>\n",
       "      <td>Port#:2</td>\n",
       "      <td>187</td>\n",
       "      <td>6304498</td>\n",
       "      <td>15713</td>\n",
       "      <td>171</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>767</td>\n",
       "      <td>688</td>\n",
       "      <td>-1</td>\n",
       "      <td>TCP-SYN</td>\n",
       "      <td>Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of:000000000000000c</td>\n",
       "      <td>Port#:3</td>\n",
       "      <td>235</td>\n",
       "      <td>6311567</td>\n",
       "      <td>8030</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>767</td>\n",
       "      <td>688</td>\n",
       "      <td>-1</td>\n",
       "      <td>TCP-SYN</td>\n",
       "      <td>Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of:000000000000000c</td>\n",
       "      <td>Port#:4</td>\n",
       "      <td>59</td>\n",
       "      <td>7878</td>\n",
       "      <td>16439</td>\n",
       "      <td>182</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>767</td>\n",
       "      <td>688</td>\n",
       "      <td>-1</td>\n",
       "      <td>TCP-SYN</td>\n",
       "      <td>Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of:000000000000000a</td>\n",
       "      <td>Port#:1</td>\n",
       "      <td>188</td>\n",
       "      <td>6304547</td>\n",
       "      <td>16497</td>\n",
       "      <td>183</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>489</td>\n",
       "      <td>403</td>\n",
       "      <td>-1</td>\n",
       "      <td>TCP-SYN</td>\n",
       "      <td>Attack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Switch ID Port Number  Received Packets  Received Bytes  \\\n",
       "0  of:000000000000000c     Port#:1               132            9181   \n",
       "1  of:000000000000000c     Port#:2               187         6304498   \n",
       "2  of:000000000000000c     Port#:3               235         6311567   \n",
       "3  of:000000000000000c     Port#:4                59            7878   \n",
       "4  of:000000000000000a     Port#:1               188         6304547   \n",
       "\n",
       "   Sent Bytes  Sent Packets  Port alive Duration (S)  Packets Rx Dropped  \\\n",
       "0     6311853           238                       46                   0   \n",
       "1       15713           171                       46                   0   \n",
       "2        8030            58                       46                   0   \n",
       "3       16439           182                       46                   0   \n",
       "4       16497           183                       46                   0   \n",
       "\n",
       "   Packets Tx Dropped  Packets Rx Errors  ...  Unknown Load/Latest  \\\n",
       "0                   0                  0  ...                    0   \n",
       "1                   0                  0  ...                    0   \n",
       "2                   0                  0  ...                    0   \n",
       "3                   0                  0  ...                    0   \n",
       "4                   0                  0  ...                    0   \n",
       "\n",
       "   Latest bytes counter  is_valid  Table ID  Active Flow Entries  \\\n",
       "0                     0      True         0                    9   \n",
       "1                     0      True         0                    9   \n",
       "2                     0      True         0                    9   \n",
       "3                     0      True         0                    9   \n",
       "4                     0      True         0                    7   \n",
       "\n",
       "   Packets Looked Up  Packets Matched  Max Size    Label  Binary Label  \n",
       "0                767              688        -1  TCP-SYN        Attack  \n",
       "1                767              688        -1  TCP-SYN        Attack  \n",
       "2                767              688        -1  TCP-SYN        Attack  \n",
       "3                767              688        -1  TCP-SYN        Attack  \n",
       "4                489              403        -1  TCP-SYN        Attack  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the data\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37411, 34)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Switch ID', 'Port Number', 'Received Packets', 'Received Bytes',\n",
       "       'Sent Bytes', 'Sent Packets', 'Port alive Duration (S)',\n",
       "       'Packets Rx Dropped', 'Packets Tx Dropped', 'Packets Rx Errors',\n",
       "       'Packets Tx Errors', 'Delta Received Packets', 'Delta Received Bytes',\n",
       "       'Delta Sent Bytes', 'Delta Sent Packets',\n",
       "       'Delta Port alive Duration (S)', 'Delta Packets Rx Dropped',\n",
       "       ' Delta Packets Tx Dropped', 'Delta Packets Rx Errors',\n",
       "       'Delta Packets Tx Errors', 'Connection Point', 'Total Load/Rate',\n",
       "       'Total Load/Latest', 'Unknown Load/Rate', 'Unknown Load/Latest',\n",
       "       'Latest bytes counter', 'is_valid', 'Table ID', 'Active Flow Entries',\n",
       "       'Packets Looked Up', 'Packets Matched', 'Max Size', 'Label',\n",
       "       'Binary Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an idea of the features  and the target\n",
    "\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical ['Switch ID', 'Port Number', 'Label', 'Binary Label'] \n",
      "numerical ['Received Packets', 'Received Bytes', 'Sent Bytes', 'Sent Packets', 'Port alive Duration (S)', 'Packets Rx Dropped', 'Packets Tx Dropped', 'Packets Rx Errors', 'Packets Tx Errors', 'Delta Received Packets', 'Delta Received Bytes', 'Delta Sent Bytes', 'Delta Sent Packets', 'Delta Port alive Duration (S)', 'Delta Packets Rx Dropped', ' Delta Packets Tx Dropped', 'Delta Packets Rx Errors', 'Delta Packets Tx Errors', 'Connection Point', 'Total Load/Rate', 'Total Load/Latest', 'Unknown Load/Rate', 'Unknown Load/Latest', 'Latest bytes counter', 'is_valid', 'Table ID', 'Active Flow Entries', 'Packets Looked Up', 'Packets Matched', 'Max Size']\n"
     ]
    }
   ],
   "source": [
    "# get numerical and categorical columns\n",
    "num_cols = list(raw_df._get_numeric_data().columns)\n",
    "categ_cols = [colum for colum in raw_df.columns if colum not in num_cols]  #easy way of getting the categorical column names\n",
    "print(\"categorical\",\n",
    "categ_cols , \"\\n\"\n",
    "\"numerical\",\n",
    "num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels for binary labels and label\n",
    "\n",
    "labels_binlab = raw_df[\"Binary Label\"]\n",
    "labels_labcat = raw_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels with values\n",
    "\n",
    "labels_binlab = labels_binlab.replace(to_replace= [\"Attack\", \"Normal\"], value= [1 , 0])\n",
    "labels_labcat = labels_labcat.replace(to_replace= ['Blackhole', 'Diversion', 'Normal', 'Overflow', 'PortScan', 'TCP-SYN'], value= [1 , 2, 3, 4, 5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all new dataframes\n",
    "\n",
    "labels_binlab.to_csv(\"../data/processed/labels_binlab.csv\", index=False)\n",
    "labels_labcat.to_csv(\"../data/processed/labels_labcat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Blackhole',\n",
       " 2: 'Diversion',\n",
       " 3: 'Normal',\n",
       " 4: 'Overflow',\n",
       " 5: 'PortScan',\n",
       " 0: 'TCP-SYN'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and use a results_dict to output the type of the attack, or normal state, as in\n",
    "# results_dict[model.predict(single_data_sample)] or query_answer = results_dict[model.predict(single_data_sample)]\n",
    "# then use query_answer to output the answer to text / email, voice message or red/green flag in dashboard.\n",
    "\n",
    "results_dict = {key : value for key, value in zip([1 , 2, 3, 4, 5, 0], ['Blackhole', 'Diversion', 'Normal', 'Overflow', 'PortScan', 'TCP-SYN'])}\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Eliminate unnecesary features. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reduced dataset without columns that provide no information.\n",
    "# dropping also switch  id and port id\n",
    "\n",
    "red_new_df = raw_df[[#'Switch ID', # this is no general info but data from setup used to model data\n",
    "                        #'Port Number', # this is no general info but data from setup used to model data\n",
    "                        'Received Packets', \n",
    "                        'Received Bytes', \n",
    "                        'Sent Bytes', \n",
    "                        'Sent Packets', \n",
    "                        'Port alive Duration (S)',\n",
    "                        #'Packets Rx Dropped', #empty feature\n",
    "                        #'Packets Tx Dropped', #empty feature\n",
    "                        #'Packets Rx Errors', #empty feature\n",
    "                        #'Packets Tx Errors', #empty feature\n",
    "                        'Delta Received Packets', \n",
    "                        'Delta Received Bytes',\n",
    "                        'Delta Sent Bytes', \n",
    "                        'Delta Sent Packets',\n",
    "                        #'Delta Port alive Duration (S)', # new # feature witn only one value for the set \n",
    "                        #'Delta Packets Rx Dropped', #empty feature\n",
    "                        #' Delta Packets Tx Dropped', #empty feature\n",
    "                        #'Delta Packets Rx Errors',#empty feature\n",
    "                        #'Delta Packets Tx Errors', #empty feature\n",
    "                        #'Connection Point', # new # information not general bur associated with test setup for data generation\n",
    "                        'Total Load/Rate',\n",
    "                        'Total Load/Latest', \n",
    "                        'Unknown Load/Rate', \n",
    "                        'Unknown Load/Latest',\n",
    "                        'Latest bytes counter', \n",
    "                        #'is_valid', # info from data generation set up\n",
    "                        #'Table ID', #empty feature\n",
    "                        #'Active Flow Entries', # new # unknown feature source not replicable in real data?\n",
    "                        'Packets Looked Up', \n",
    "                        'Packets Matched', \n",
    "                        #'Max Size', # # unknown feature source not replicable in real data?\n",
    "                        'Label',\n",
    "                        'Binary Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save  new reduced dataset as a dataframe\n",
    "\n",
    "red_new_df.to_csv(\"../data/processed/red_new_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the label columns creating the reduced features dataframe\n",
    "\n",
    "red_new_features = red_new_df.drop(['Label', \"Binary Label\"], axis=1)\n",
    "red_new_features.to_csv(\"../data/processed/red_new_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Select an appropriate ML classification model for the task and the data. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test data for multi class labels \n",
    "\n",
    "X_red_new_train, X_red_new_test, y_red_new_train, y_red_new_test = train_test_split(red_new_features,labels_labcat, random_state= 0 , test_size= 0.2)\n",
    "\n",
    "# save the test and train sets\n",
    "\n",
    "sets = [X_red_new_train,X_red_new_test,y_red_new_train,y_red_new_test]\n",
    "names = list(str(\"X_red_new_train,X_red_new_test,y_red_new_train,y_red_new_test\").split(','))\n",
    "for idx in range(len(sets)):\n",
    "    sets[idx].to_csv(\"../data/processed/\" + names[idx] + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Run simple logistic regression model on train and test it. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.13      0.22      1808\n",
      "           1       0.34      0.11      0.17      1681\n",
      "           2       0.27      0.86      0.41      1111\n",
      "           3       0.44      0.99      0.61       770\n",
      "           4       0.05      0.05      0.05       202\n",
      "           5       0.67      0.41      0.51      1911\n",
      "\n",
      "    accuracy                           0.39      7483\n",
      "   macro avg       0.41      0.42      0.33      7483\n",
      "weighted avg       0.49      0.39      0.34      7483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# run Logistic Regression model for multi class labels WITHOUT STANDARIZATION\n",
    "\n",
    "lgr_no_pipeline = Pipeline(steps = [ \n",
    "        (\"logistic_regression\", LogisticRegression(class_weight= \"balanced\", random_state= 0, max_iter = 4000))])\n",
    "\n",
    "\n",
    "lgr_no_pipeline.fit(X_red_new_train, y_red_new_train)\n",
    "y_red_new_pred = lgr_no_pipeline.predict(X_red_new_test)\n",
    "print(classification_report(y_red_new_test, y_red_new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75      1808\n",
      "           1       0.70      0.54      0.61      1681\n",
      "           2       0.56      0.55      0.55      1111\n",
      "           3       1.00      1.00      1.00       770\n",
      "           4       0.11      0.59      0.19       202\n",
      "           5       0.90      0.53      0.67      1911\n",
      "\n",
      "    accuracy                           0.66      7483\n",
      "   macro avg       0.66      0.67      0.63      7483\n",
      "weighted avg       0.74      0.66      0.68      7483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run Logistic Regression model for multi class labels WITH STANDARIZATION\n",
    "lgr_yes_pipeline = Pipeline(steps = [ (\"numeric\", StandardScaler() ),\n",
    "        (\"logistic_regression\", LogisticRegression(class_weight= \"balanced\", random_state= 0, max_iter = 600))])\n",
    "\n",
    "\n",
    "lgr_yes_pipeline.fit(X_red_new_train, y_red_new_train)\n",
    "y_yes_red_new_pred = lgr_yes_pipeline.predict(X_red_new_test)\n",
    "print(classification_report(y_red_new_test, y_yes_red_new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Perform TPOT analysis and select a better model, fine tuned. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TPOT in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (0.11.7)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.4.3)\n",
      "Requirement already satisfied: deap>=1.2 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.3.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.22.4)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (4.64.1)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.1.0)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.1.2)\n",
      "Requirement already satisfied: update-checker>=0.16 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (0.18.0)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from TPOT) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from pandas>=0.24.2->TPOT) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from pandas>=0.24.2->TPOT) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from scikit-learn>=0.22.0->TPOT) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from update-checker>=0.16->TPOT) (2.28.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->TPOT) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (2022.9.24)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad668d34d0f947c19506105e8748f087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/48 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8883656183559466\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.905239465743097\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.905239465743097\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.905239465743097\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9093493283269428\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=False, criterion=gini, max_features=0.3, min_samples_leaf=8, min_samples_split=4, n_estimators=100)\n",
      "Tpop score on test data: 0.91\n",
      "CPU times: user 18min 25s, sys: 1min 25s, total: 19min 50s\n",
      "Wall time: 16min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaquingianantonio/tensor_flow/env2/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:765: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, \n",
    "                      population_size=8,\n",
    "                      scoring=None,\n",
    "                      verbosity=2,\n",
    "                      random_state=42)\n",
    "tpot.fit(X_red_new_train, y_red_new_train)\n",
    "print(f\"Tpop score on test data: {tpot.score(X_red_new_test, y_red_new_test):.2f}\")\n",
    "tpot.export('tpot_network_analytics.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
      "features = tpot_data.drop('target', axis=1)\n",
      "training_features, testing_features, training_target, testing_target = \\\n",
      "            train_test_split(features, tpot_data['target'], random_state=42)\n",
      "\n",
      "# Average CV score on the training set was: 0.9093493283269428\n",
      "exported_pipeline = RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.3, min_samples_leaf=8, min_samples_split=4, n_estimators=100)\n",
      "# Fix random state in exported estimator\n",
      "if hasattr(exported_pipeline, 'random_state'):\n",
      "    setattr(exported_pipeline, 'random_state', 42)\n",
      "\n",
      "exported_pipeline.fit(training_features, training_target)\n",
      "results = exported_pipeline.predict(testing_features)\n"
     ]
    }
   ],
   "source": [
    "cat tpot_network_analytics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=1.0, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=8,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=42, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=1.0, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=8,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=42, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=1.0, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=8,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=1, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', random_state=42, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train xgboos classifier model recommended by TPOT // MODEL PARAMETERS TAKEN FROM ANOTHER TPOT RUN\n",
    "\n",
    "model_xgbc_01 = XGBClassifier(learning_rate=1.0, max_depth=5, min_child_weight=8, n_estimators=100, n_jobs=1, subsample=0.8500000000000001, verbosity=0)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(model_xgbc_01, 'random_state'):\n",
    "    setattr(model_xgbc_01, 'random_state', 42)\n",
    "\n",
    "model_xgbc_01.fit(X_red_new_train, y_red_new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1808\n",
      "           1       0.99      0.98      0.98      1681\n",
      "           2       0.98      0.97      0.98      1111\n",
      "           3       1.00      1.00      1.00       770\n",
      "           4       0.97      0.82      0.89       202\n",
      "           5       0.91      0.93      0.92      1911\n",
      "\n",
      "    accuracy                           0.95      7483\n",
      "   macro avg       0.96      0.94      0.95      7483\n",
      "weighted avg       0.95      0.95      0.95      7483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check metrics for trained model\n",
    "\n",
    "results_new_red = model_xgbc_01.predict(X_red_new_test) # eview data names\n",
    "print(classification_report(y_red_new_test, results_new_red)) # review data names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_xgbc_01.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save fina model with joblib\n",
    "\n",
    "joblib.dump(model_xgbc_01, \"model_xgbc_01.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      "        Received Packets  Received Bytes  Sent Bytes  Sent Packets  \\\n",
      "19668               449         6335491       33279           289   \n",
      "\n",
      "       Port alive Duration (S)  Delta Received Packets  Delta Received Bytes  \\\n",
      "19668                      284                       4                   556   \n",
      "\n",
      "       Delta Sent Bytes  Delta Sent Packets  Total Load/Rate  \\\n",
      "19668               560                   4                0   \n",
      "\n",
      "       Total Load/Latest  Unknown Load/Rate  Unknown Load/Latest  \\\n",
      "19668                  0                  0                    0   \n",
      "\n",
      "       Latest bytes counter  Packets Looked Up  Packets Matched  \n",
      "19668                     0               2494             2338   \n",
      " 19668    2\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get one sample data point from the test set by entering the sample id, valid id in range(len(test_data))\n",
    "# def get_test_sample(sample_id):\n",
    "\n",
    "sam = 345\n",
    "sample1 = X_red_new_test.iloc[[sam]]\n",
    "tag1 = y_red_new_test.iloc[[sam]]\n",
    "print(type(sample1),\"\\n\", sample1, \"\\n\",tag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:blue\"> when preparing the clean version of the notebook tpot returned a different ensembled tree classificator.  trying it out here. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1808\n",
      "           1       0.96      0.96      0.96      1681\n",
      "           2       0.97      0.91      0.94      1111\n",
      "           3       1.00      1.00      1.00       770\n",
      "           4       0.94      0.49      0.64       202\n",
      "           5       0.88      0.89      0.89      1911\n",
      "\n",
      "    accuracy                           0.91      7483\n",
      "   macro avg       0.93      0.86      0.88      7483\n",
      "weighted avg       0.92      0.91      0.91      7483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "exported_pipeline = RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.3, min_samples_leaf=8, min_samples_split=4, n_estimators=100)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(exported_pipeline, 'random_state'):\n",
    "    setattr(exported_pipeline, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(X_red_new_train, y_red_new_train)\n",
    "results_rmdf = exported_pipeline.predict(X_red_new_test)\n",
    "print(classification_report(y_red_new_test, results_rmdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:blue\"> Metrics from the xgboost ensembled classifier are better.  We continue using xgboost. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "290095bb742939b88273a8583276d7630b426f870a564acf8afa069dfccd475a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
