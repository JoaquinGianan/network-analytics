{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.color_palette()\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports 4\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Read and prepare the UNNID data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have an idea of the size of the data\n",
    "%%sh\n",
    "wc -l ../data/raw/UNR-IDD.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data as pd dataframe\n",
    "\n",
    "rawdata_path = \"../data/raw/UNR-IDD.csv\"\n",
    "raw_df = pd.read_csv(rawdata_path, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw_df as csv to folder for further use\n",
    "\n",
    "raw_df.to_csv(\"../data/raw/raw_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an idea of the features  and the target\n",
    "\n",
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numerical and categorical columns\n",
    "num_cols = list(raw_df._get_numeric_data().columns)\n",
    "categ_cols = [colum for colum in raw_df.columns if colum not in num_cols]  #easy way of getting the categorical column names\n",
    "print(\"categorical\",\n",
    "categ_cols , \"\\n\"\n",
    "\"numerical\",\n",
    "num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels for binary labels and label\n",
    "\n",
    "labels_binlab = raw_df[\"Binary Label\"]\n",
    "labels_labcat = raw_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels with values\n",
    "\n",
    "labels_binlab = labels_binlab.replace(to_replace= [\"Attack\", \"Normal\"], value= [1 , 0])\n",
    "labels_labcat = labels_labcat.replace(to_replace= ['Blackhole', 'Diversion', 'Normal', 'Overflow', 'PortScan', 'TCP-SYN'], value= [1 , 2, 3, 4, 5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and use a results_dict to output the type of the attack, or normal state, as in\n",
    "# results_dict[model.predict(single_data_sample)] or query_answer = results_dict[model.predict(single_data_sample)]\n",
    "# then use query_answer to output the answer to text / email, voice message or red/green flag in dashboard.\n",
    "\n",
    "results_dict = {key : value for key, value in zip([1 , 2, 3, 4, 5, 0], ['Blackhole', 'Diversion', 'Normal', 'Overflow', 'PortScan', 'TCP-SYN'])}\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all new dataframes\n",
    "\n",
    "labels_binlab.to_csv(\"../data/processed/labels_binlab.csv\", index=False)\n",
    "labels_labcat.to_csv(\"../data/processed/labels_labcat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reduced dataset without columns that provide no information.\n",
    "# dropping also switch  id and port id\n",
    "\n",
    "red_new_df = raw_df[[#'Switch ID', # this is no general info but data from setup used to model data\n",
    "                        #'Port Number', # this is no general info but data from setup used to model data\n",
    "                        'Received Packets', \n",
    "                        'Received Bytes', \n",
    "                        'Sent Bytes', \n",
    "                        'Sent Packets', \n",
    "                        'Port alive Duration (S)',\n",
    "                        #'Packets Rx Dropped', #empty feature\n",
    "                        #'Packets Tx Dropped', #empty feature\n",
    "                        #'Packets Rx Errors', #empty feature\n",
    "                        #'Packets Tx Errors', #empty feature\n",
    "                        'Delta Received Packets', \n",
    "                        'Delta Received Bytes',\n",
    "                        'Delta Sent Bytes', \n",
    "                        'Delta Sent Packets',\n",
    "                        #'Delta Port alive Duration (S)', # new # feature witn only one value for the set \n",
    "                        #'Delta Packets Rx Dropped', #empty feature\n",
    "                        #' Delta Packets Tx Dropped', #empty feature\n",
    "                        #'Delta Packets Rx Errors',#empty feature\n",
    "                        #'Delta Packets Tx Errors', #empty feature\n",
    "                        #'Connection Point', # new # information not general bur associated with test setup for data generation\n",
    "                        'Total Load/Rate',\n",
    "                        'Total Load/Latest', \n",
    "                        'Unknown Load/Rate', \n",
    "                        'Unknown Load/Latest',\n",
    "                        'Latest bytes counter', \n",
    "                        #'is_valid', # info from data generation set up\n",
    "                        #'Table ID', #empty feature\n",
    "                        #'Active Flow Entries', # new # unknown feature source not replicable in real data?\n",
    "                        'Packets Looked Up', \n",
    "                        'Packets Matched', \n",
    "                        #'Max Size', # # unknown feature source not replicable in real data?\n",
    "                        'Label',\n",
    "                        'Binary Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save  new dataset\n",
    "\n",
    "red_new_df.to_csv(\"../data/processed/red_new_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the label columns creating the reduced features dataframe\n",
    "\n",
    "red_new_features = red_new_df.drop(['Label', \"Binary Label\"], axis=1)\n",
    "red_new_features.to_csv(\"../data/processed/red_new_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Select an appropriate ML classification model for the task and the data. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test data for multi class labels \n",
    "\n",
    "X_red_new_train_cat, X_red_new_test_cat, y_red_new_train_cat, y_red_new_test_cat = train_test_split(red_new_features,labels_labcat, random_state= 0 , test_size= 0.2)\n",
    "\n",
    "# save the test and train sets\n",
    "\n",
    "sets = [X_red_new_train_cat,X_red_new_test_cat,y_red_new_train_cat,y_red_new_test_cat]\n",
    "names = list(str(\"X_red_new_train_cat,X_red_new_test_cat,y_red_new_train_cat,y_red_new_test_cat\").split(','))\n",
    "for idx in range(len(sets)):\n",
    "    sets[idx].to_csv(\"../data/processed/\" + names[idx] + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Run simple logistic regression model on train and test it. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Logistic Regression model for multi class labels WITHOUT STANDARIZATION\n",
    "\n",
    "lgr_no_pipeline_cat = Pipeline(steps = [ \n",
    "        (\"logistic_regression\", LogisticRegression(class_weight= \"balanced\", random_state= 0, max_iter = 4000))])\n",
    "\n",
    "\n",
    "lgr_no_pipeline_cat.fit(X_red_new_train_cat, y_red_new_train_cat)\n",
    "y_red_new_pred_cat = lgr_no_pipeline_cat.predict(X_red_new_test_cat)\n",
    "print(classification_report(y_red_new_test_cat, y_red_new_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Logistic Regression model for multi class labels WITH STANDARIZATION\n",
    "lgr_yes_pipeline_cat = Pipeline(steps = [ (\"numeric\", StandardScaler() ),\n",
    "        (\"logistic_regression\", LogisticRegression(class_weight= \"balanced\", random_state= 0, max_iter = 600))])\n",
    "\n",
    "\n",
    "lgr_yes_pipeline_cat.fit(X_red_new_train_cat, y_red_new_train_cat)\n",
    "y_yes_red_new_pred_cat = lgr_yes_pipeline_cat.predict(X_red_new_test_cat)\n",
    "print(classification_report(y_red_new_test_cat, y_yes_red_new_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:green\"> Perform TPOT analysis and select a better model, fine tuned. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the names of the data files used in the analysis, do not use binary labels: use multi-labels\n",
    "\n",
    "%%time\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, \n",
    "                      population_size=8,\n",
    "                      scoring=None,\n",
    "                      verbosity=2,\n",
    "                      random_state=42)\n",
    "tpot.fit(X_train_bin, y_train_bin)\n",
    "print(f\"Tpop score on test data: {tpot.score(X_test_bin, y_test_bin):.2f}\")\n",
    "tpot.export('tpot_network_analytics.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat tpot_network_analytics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train xgboos classifier model recommended by TPOT // MODEL PARAMETERS TAKEN FROM ANOTHER TPOT RUN\n",
    "\n",
    "model_jg_01 = XGBClassifier(learning_rate=1.0, max_depth=5, min_child_weight=8, n_estimators=100, n_jobs=1, subsample=0.8500000000000001, verbosity=0)\n",
    "# Fix random state in exported estimator\n",
    "if hasattr(model_jg_01, 'random_state'):\n",
    "    setattr(model_jg_01, 'random_state', 42)\n",
    "\n",
    "model_jg_01.fit(X_red_new_train_cat, y_red_new_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metrics for trained model\n",
    "\n",
    "results_new_red = model_jg_01.predict(X_red_new_test_cat) # eview data names\n",
    "print(classification_report(y_red_new_test_cat, results_new_red)) # review data names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fina model with joblib\n",
    "\n",
    "joblib.dump(model_jg_01, \"model_jg_01.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one sample data point from the test set by entering the sample id, valid id in range(len(test_data))\n",
    "# def get_test_sample(sample_id):\n",
    "\n",
    "sam = 345\n",
    "sample1 = X_red_new_test_cat.iloc[[sam]]\n",
    "tag1 = y_red_new_test_cat.iloc[[sam]]\n",
    "type(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
